\documentclass{article}
\usepackage{arxiv}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}


\title{Классификация товаров по ОКПД2 кодам}

\author{ Фирсов Сергей Андреевич\\
        Кафедра интеллектуальных систем\\
	МФТИ\\
	\texttt{firsov.sa@phystech.edu} \\
	\And
        Вознюк Анастасия Евгеньевна \\
	Кафедра интеллектуальных систем \\
        МФТИ \\
        \texttt{vozniuk.ae@phystech.edu} \\
	\AND
	Старожилец Всеволод Михайлович  \\
	Кафедра интеллектуальных систем\\
	Антирутина\\
	\texttt{vsevolod.starozhilets@antirutina.net} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{}


%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    pdftitle={Классификация товаров по ОКПД 2 кодам},
    %pdfsubject={hierarchical classification, embeddings, logarithmic regression},
    pdfauthor={Фирсов Сергей, Старожилец Всеволод, Вознюк Анастасия},
    pdfkeywords={hierarchical classification, embeddings, logarithmic regression},
}

\newcommand{\customcite}[2]{\footnote{#2, see \cite{#1}}}
%\bibliographystyle{plain}
\bibliographystyle{unsrt}

\begin{document}
\maketitle

\begin{abstract}
    Исследование посвящено классификации товаров по кодам Общероссийского классификатора продукции по видам экономической деятельности (ОКПД 2), используя краткие текстовые описания. Основной целью является повышение точности и оптимизация ресурсов в процессе классификации за счёт анализа глубины кодов ОКПД2. Работа предлагает метод построения текстовых эмбеддингов, который способствует улучшению классификационных процессов в сфере логистики и учёта. В работе рассмотрены улучшения этого метода, основанные на иерархической структуре входных данных.
\end{abstract}


\keywords{ОКПД 2 коды  \and многоклассовая классификаци \and иерархическая классификация \and эмбеддинги\and логистическая регрессия}

\section{Введение}

Целью данного исследования является разработка и апробация метода классификации товаров по кодам ОКПД 2\footnote{Общероссийский классификатор продукции по видам экономической деятельности, \href{https://classifikators.ru/okpd}{сайт}}, используя краткие текстовые описания. Основная идея заключается в построении эмбеддингов и дальнейшем решении задачи многоклассовой классификации. Актуальность задачи обусловлена необходимостью повышения эффективности процессов логистики и учета в сфере закупок, а также сокращения времени и ресурсов, затрачиваемых на классификацию товаров. %\textit{(АКТУАЛЬНОСТЬ!!!! )}



Наиболее релевантными работами к данному исследованию оказались \cite{Marra2021AutomaticClassification}, \cite{Lewis2004ReutersCodes} \cite{Haav2021HSCodes}. В этих работах исследуется многоклассовая классификация по различным кодам. Наиболее часто встречаются модели ---  логистическая регрессия и нейронные сети. Также в \cite{Marra2021AutomaticClassification} уделено внимание дообучающимся моделям, таким как GPT-3.5, GPT-4 --- они работают лучше остальных с текстами плохого качества, т.е. в которых есть словами или символы неизвестные модели эмбеддингов. В этих статьях при работе с текстом описываются варианты пострения эмбеддингов, фигурируют методы Word2Vec и Glove и различные оболочки, поддерживающие эти методы.  

Анализ методов построения эмбеддингов \cite{liu2018word} \cite{bird2009natural} привёл к всё тем же методам Word2Vec\cite{Church2017}\cite{DiGennaro2021} или GloVe\cite{munozWordEmbeddings}.  Эти методы используют нейронные сети и стараются либо предугадать пропущеное слово по контексту, либо восстановить контекст по слову.  Стоит выделить предобученные модели, такие как BERT, они адаптированны под специфику языка \cite{Lee2022Transformer} и дообучаются на входных данных. Таким образом обеспечивают дополнительное преимущество за счёт учёта лингвистических особенностей.

В работе предлагается использовать библиотеку spaCy\cite{spacy2} для построение эмбеддингов. Библиотека основана на вышеописанных методах и имеет предобученные модели, готовые для взаимодействия с русским языком. После построения эмбендингов --- решается задача классификации, с помощью логистической регрессии. Дальше исследуется качество классификации варьируя глубину классификатора --- что и есть основная суть исследования. Для улучшения качества предлагается идея иерархической классификации \cite{JStextclass2022} \cite{versley2006hierarchical} \cite{sebastiani2020hierarchical}.
%\footnote{Официальная документация \href{https://spacy.io/}{spaCy}} 

\section{Постановка задачи}

В данной части обсудим формальное теоретическое описание задачи  и предлагаемого решения.

\textbf{Основные термины}:
\begin{itemize}
    \item ОКПД 2 (Общероссийский классификатор продукции по видам экономической деятельности) -- система классификации, используемая для каталогизации продукции.
    \item Эмбеддинги --- векторные представления слов. Векторы отражают семантическое значение каждого слова на основе контекста.
    \item Описание товара --- короткий текст, составленные людьми при оформлении продажи товара.
    \item Префиксы кода длины N (далее ``префикс N``) --- первые N цифр ОКПД2 кода
    %\item Ступени классификатора --- негласное разделение кода на части, удобное при анализе качества от глубины. К примеру --- код 12.34.56.789, 1-я ступень --- 12, 2-я ступень --- 1234, и так далее. 
\end{itemize}

В данной работе рассматривается задача многоклассовой классификации текстовых описаний товаров для определения их соответствия классам кодам ОКПД2. 

\subsection{Выборка}
Выборка представлена парами ``текстовое описание товара --- код ОКПД2``. 
\begin{equation}
\mathfrak{D}  = \{(\bold{x}_i, y_i)\}_{i=1}^{m},\; \bold{x}_i = \texttt{ \{t_i\}_{j=1}^{n}} - \texttt{текстовое описание},\; y_i \in \mathbf{Y}  = \{1, \dots, k\}. %sequence of words
\end{equation}
Выборка разбита на обучающую и тестовую части: $\mathfrak{D} = \mathfrak{D}_\text{train} \bigsqcup \mathfrak{D}_\text{test}$.
%можно убрать
\subsection{Ограничения и другие предположения о характере данных}
\begin{itemize}
  \item[\circ] Количество записей $m \approx 8$ миллионов, количество классов $k \approx 5000$. 
  \item[\circ] Структура классов несбалансирована: для некоторых классов доступно до 1000 записей, в то время как для других --- более 200000. 
  \item[\circ] Текстовые описания часто содержат узкоспециализированную лексику, жаргонизмы, артикли и числовые значения, что усложняет задачу классификации.
\end{itemize}
Исходя из особенностей текстовых данных, принимается во внимание, что не все части описаний могут быть одинаково информативными для каждого класса, и необходимо отказаться от некоторых элементов описаний и даже от несущественных классов.
\subsection{Определение модели}

Используется модель логистической регрессии, она моделирует вероятность принадлежности наблюдения к одному из классов. Обычно она используется для бинарной классификации, но может обобщаться на многоклассовую разными способами --- в работе выбрана \texttt{OVR} схема (\texttt{one-versus-rest}\cite{9099858}). В случае многоклассовой классификации, модель определяется как:
\begin{equation}
    P(y=1 | \mathbf{x}; \boldsymbol{\theta_k}) = \sigma(\mathbf{x}^\top \boldsymbol{\theta_k}),
\end{equation}
где $\mathbf{x}$ обозначает вектор признаков наблюдения (с предварительно добавленной единицей для учета свободного члена), $\boldsymbol{\theta_k}$ --- вектор параметров модели для класса $k$, а $\sigma(z) = \frac{1}{1 + e^{-z}}$ --- сигмоидная функция. Обучается отдельная логистическая модель для каждого класса, сравнивающая этот класс со всеми остальными классами. Класс с наибольшей предсказанной вероятностью выбирается в качестве итогового предсказания для объекта.

\subsection{Функция потерь}

Функция потерь для логистической регрессии --- это логистическая потеря (log-loss), которая для нашей можели выражается как:
\begin{equation}
    \mathcal{L}(\boldsymbol{\theta_k}) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\sigma(\mathbf{x}_i^\top \boldsymbol{\theta_k})) + (1 - y_i) \log(1 - \sigma(\mathbf{x}_i^\top \boldsymbol{\theta_k})) \right],
\end{equation}
где $N$ --- число наблюдений в подвыборке, $y_i$ --- истинная метка класса для наблюдения $i$.

\subsection{Задача оптимизации}

Задача оптимизации для логистической регрессии формулируется как поиск оптимального вектора параметров $\boldsymbol{\theta_k}$, минимизирующего функцию потерь:
\begin{equation}
    \boldsymbol{\theta_k}^* = \arg\min_{\boldsymbol{\theta_k}} \mathcal{L}(\boldsymbol{\theta_k}).
\end{equation}


\subsection{Критерии качества}

Для анализа качества модели используются ROC\cite{fawcett2006introduction} и Precision-Recall\cite{amigo2018general} кривые, позволяющие оценить баланс между чувствительностью модели и её способностью корректно классифицировать объекты разных классов. Анализ площади под этими кривыми (\texttt{roc-auc} и \texttt{pr-auc}) дает количественную оценку эффективности модели.


\section{Решение}
\subsection{Свойства модели или предлагаемого решения}

Для анализа текстовых данных и классификации используется модель логистической регрессии, реализованная в библиотеке \textit{scikit-learn}\footnote{По этой \href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html}{ссылке} находится используемая модель}. Логистическая регрессия выбрана за её способность эффективно работать с высокоразмерными данными и выделять линейные зависимости между признаками и целевыми классами. Библиотека поддерживает мультиклассовую классификацию методом \texttt{ovr}, а также считает интересующие нас метрики ROC и Precision-Recall.

Для преобразования текстов в векторизованное представление используются эмбеддинги, полученные с помощью библиотеки \texttt{spaCy}. Это позволяет преобразовать исходный текст в  векторное пространство, где каждое измерение содержит некоторую семантическую информацию о слове, что значительно улучшает качество классификации.

\subsection{Описание алгоритма получения решения}

Процесс решения задачи классификации состоит из нескольких этапов:
\begin{enumerate}
    \item Предварительная обработка данных: очистка текста от шума, нормализация и токенизация.
    \item Фильтрация данных, для улучшения свойств выборки.
    \item Преобразование текстов в векторное представление с использованием эмбеддингов \texttt{spaCy}.
    \item Обучение модели логистической регрессии на обработанных данных.
    \item Оценка качества модели с roc-auc и pr-auc.
\end{enumerate}


\section{Вычислительный эксперимент}
\subsection{Цель эксперимента}
Цель эксперимента построить модель логистической регресии и  исследовать её работу в зависимости от глубины классификатора. Также необходимо провести два эксперимента с применением иерархической классификации: мы достаточно хорошо должны уметь прогнозировать первые несколько цифр кода, а так как данные имеют иерархическую структуру, хотелось бы использовать результаты предсказания первых цифр при предсказании дальнейших.
\begin{itemize}
    \item Эксперимент 1: Будем добавлять предсказанные цифры в вектор признаков. Так как эмбеддинги --- это вектора, каждый элемент которых - число от 0 до 1, а номер класса - число от 1 до 1000 или даже больше, модель будет обращать внимание на этот признак и учитывать его.
    \item Эксперимент 2: Будем разделять выборку на подклассы, по результатам классификации по первым цифрам. Далее для каждого класса - обучаем свою модель. Эта идея похожа на предыдущую, она по сути представляет собой более строгое использование результата предыдущей классификации. 
    
\end{itemize}


\subsection{Описание постановки и условий эксперимента}
\begin{itemize}
    \item[\circ] В качестве реализации модели лог регрессии выбрана библиотека \texttt{sklearn} и её \texttt{sklearn.linear\_model.LogisticRegression}
    \item[\circ] Для построения эмбеддингов выбрана библиотека \texttt{spaCy} и её предобученная модель \texttt{ru\_core\_news\_lg}. Стоит оговориться:
    \begin{itemize}
        \item Проводились отдельные эксперименты с библиотекой \texttt{gensim}, для получения другой вариации эмбеддингов. Но результаты классификации оказались значительно хуже\footnote{\href{https://github.com/intsystems/2024-Project-142/blob/master/code}{Здесь} представлены все результаты экспериментов}.
        \item Размерность векторов эмбеддингов сильно влияет на классификацию. В экспериментах выбрана размерность 300, как оптимальная для использования \texttt{large} модели из \texttt{spaCy}.
        \item Выбор именно этой предобученной модели, был обоснован сравнением качества эмбеддингов полученных с помощью \texttt{large} и \texttt{small} моделей.%\footnote{\href{https://github.com/intsystems/2024-Project-142/blob/master/code/after_talk-2_lg_embeddings_200k.ipynb}{Файл} с результатами lg модели (прямое сравнение добавлю позже, будет с bert ещё)}.
    \end{itemize}
    
    %\item[\circ]
    %\item[\circ]
\end{itemize}
\subsection{Описание данных и их обработка}
Изначально данные --- это пары значений: текстовое описание товара и его ОКПД2 код. Эти описания были составлены людьми, содержат орфографические ошибки, лишние символы, артикулы, цифры и много другое. Необходимо произвести предобработку:
\begin{itemize}
\item[\circ] Данные привели к однотипному формату: убрали склонения, заглавные буквы, почистили от незначащих символов, артикулов.%\footnote{\href{https://github.com/intsystems/2024-Project-142/blob/master/code/preparing_data.ipynb}{Файл} с предобработкой}.
%\item[\circ] В данных добавлены промежуточные ступени классификатора: полный код --- это 9 цифр, пример 12.34.56.789. Разбиваем его на числовые значения по ступеням: 1 ступень --- 12, ступень 1.5 --- 123, ступень 2 --- 1234, ступень 2.5 --- 12345 и т.д.. 
\item[\circ] Данных очень много, так что из-за вычислительной сложности эксперимента было решено выделить несколько классов для анализа их классификации. \footnote{Выбор пал на 1,17,33,45,58,81,86 классы по первым двум цифрам кода. Это : 01 --- Продукция и услуги сельского хозяйства и охоты, 17 --- Бумага и изделия из бумаги, 33 --- Услуги по ремонту и монтажу машин и оборудования, 45 --- Услуги по оптовой и розничной торговле и услуги по ремонту автотранспортных средств и мотоциклов,  58 --- Услуги издательские,  81 --- Услуги по обслуживанию зданий и территорий, 86 --- Услуги в области здравоохранения}  
\item[\circ] Данные прошли фильтрацию для избавления от слишком мелких классов, чтобы снизить дизбаланс классов и улучшить качество классификации.
\end{itemize}
Итоговая подвыборка после предобработки, используемая в большинстве экспериментов, сформирована и загружена отдельно.%\footnote{Для воспроизведения экспериментов рекомендуется использовать этот \href{https://drive.google.com/file/d/12_fNYtyjWvP5SuHyTfmj7NbKX617Lamg/view?usp=sharing}{файл}}.

\newpage
\subsection{Ход эксперимента}

\begin{enumerate}
    \item[0.] Для всех данных построены эмбеддинги.
    \item Эксперимент 1, выборка 1\footnote{Подвыборка включающая 33,45,81,86 классы по первым двум цифрам}.
     \begin{enumerate}
        \item По обучающей выборке обучены модели логистической регрессии, в качестве ответов выбраны префиксы кодов длиной от 3 до 7. (соответственно обучено 5 моделей)
        \item Для каждой модели и каждого класса построены presign-recall и roc - кривые
     \end{enumerate}
   
     \item Эксперимент 2, выборка 2\footnote{Подвыборка включающая 1,17,33 классы по первым двум цифрам}.
     \begin{enumerate}
      \item По обучающей выборке обучены модели логистической регрессии, в качестве ответов выбраны префиксы кодов длиной от 3 до 7. (соответственно обучено 5 моделей)
      \item Для каждой модели и каждого класса построены presign-recall и roc - кривые
     \end{enumerate}
    
    \item Для выборки 2 проведено два эксперимента с проверкой иерархической идеи улучшения:
    \begin{enumerate}
        \item Полученные результаты после классификации по префиксу кода длиной 3 добавлены в вектор признаков. Теперь по увеличенному вектору признаков (эмбеддинги + predicted-1-step) обучаются модели логистической регрессии,, в качестве ответов выбраны префиксы кодов длиной от 3 до 6.
        \item Все данные разделены по подклассам, определённым после классификации по префиксу кода длиной 3. Для каждого подкласса обучаются отдельные модели лог регрессии, в качестве ответов выбраны префиксы кодов длиной от 3 до 6.
    \end{enumerate}
    \item Для анализа ошибок этих экспериментов - подсчитаны количества неправильных ответов моделей, в зависимости от длины префикса кода. 
\end{enumerate}


\subsection{Анализ полученных результатов}
\begin{itemize}
    \item По результатам пункта 2 раздела 4.4 была замечена основная тенденция обучения: вне зависимости от глубины, большие классы хорошо отделяются от остальных, точность падает на более длинных префиксах кода, но до допустимых значений $\approx0.5$. Для маленьких классов, модель часто не справляется.
    \item На рисунках \ref{fig:pr1} и \ref{fig:roc1} - PR и ROC кривые для всех классов префикса кода длиной 3. Видим, что все ROC-кривые показывают отличные результаты. Видим, что все PR-кривые показывают хороший результат, кроме 3 и 4 классов, соответствующих "услугам по ремонту и обслуживанию машин и спец техники" . После анализа, выявлено содержание множества некачественных текстов, среди описаний товаров этих классов, по которым сроятся некачественные эмбеддинги. В дальнейших экспериментах был убран этот класс из рассмотрения, до возможности дообучения эмбеддингов на наших данных.
    
\end{itemize}

\begin{figure}[!ht]
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{pr_with_bad.png}
        \caption{PR-кривые для всех классов, префикс 3, выборка 1}
        \label{fig:pr1}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.54\textwidth}
        \centering
        \includegraphics[width=\linewidth]{roc_with_bad.png}
        \caption{ROC-кривые для всех классов, префикс 3, выборка 1}
        \label{fig:roc1}
    \end{minipage}
\end{figure}

\begin{itemize}
    \item По результам пункта 5, наблюдаем подтверждение тенденции качественного отделения больших классов и видим улучшение результатов классификации при исключении классов с плохими данными. На рисунке \ref{fig:pr2} - показаны pr-кривые для всех классов префикса кода длиной 3 выборки 2, видим хорошие показатели разделения. 
    \item На рисунке \ref{fig:pr3} - показаны pr-кривые для одного из классов в зависимости от глубины классификации. Видим закономерное ухудшение результата классификации при увеличении длины префикса кода, при этом даже при предсказании целого кода результаты удовлетворительные.  
\end{itemize} 


\begin{figure}[!ht]
        \centering
        \includegraphics[width=\linewidth]{pr_good.png}
        \caption{PR-кривые для всех классов, префикс 3, выборка 2}
        \label{fig:pr2}
\end{figure}
\begin{figure}[!ht]
        \centering
        \includegraphics[width=\linewidth]{pr_curve_1.png}
        %\caption{PR-кривые для всех классов, ступень 1.5, выборка 2}
        \label{fig:pr3}
\end{figure}

\begin{itemize}
    \item По результатам экспериментов  с проверкой иерархической идеи улучшения классификации получена сводная таблица \ref{tab:1}. В ней показаны количества ошибок (в тысячах), на выборке 2 в зависимости от метода: стандартный, с разбиением выборки на подклассы, с добавлением нового признака. Размер выборки 2 --- 736 тыс. записей.
    
    \begin{table}[ht]
        \centering
        \begin{tabular}{|l|c|c|c|}
            \hline
            \textbf{Метод} & \textbf{Стандартный} & \textbf{С разбиением на подклассы} & \textbf{С добавлением признака} \\ \hline
            Префикс 4 & 90 & \textbf{86} & 87 \\ \hline
            Префикс 5 & 106 & \textbf{101} & 103 \\ \hline
            Префикс 6 & 120 & \textbf{112} & 113 \\ \hline
        \end{tabular}
        \caption{Количество ошибок на выборке 2 в зависимости от метода и длины префикса}
        \label{tab:1}
    \end{table}
    
    \item В таблице \ref{tab:1} наблюдается  рост количества ошибок с увеличением длины префикса. Также видим, что предлагаемые методы иерархической классификации улучшают результаты --- наблюдаем уменьшение количества ошибок примерно на 5\%. Чуть лучше себя показывает метод с разбиением на подклассы, как и предполагалось. 
\end{itemize}


\subsection{Выводы}
\begin{itemize}
    \item Модели были построены на различных выборках, и результаты показали, что для крупных классов модель демонстрирует высокую точность, что соответствует целям исследования.
    \item Анализ зависимости качества классификации от глубины классификатора подтвердил ожидаемые тенденции: с увеличением глубины точность падает, но остаётся в приемлемых пределах.
    \item Реализация и тестирование улучшенных методов классификации показали снижение количества ошибок на 5\%, что указывает на положительное влияние предложенных усовершенствований.
\end{itemize}
Все эксперименты поддерживают повторяемость и могут быть проверены и проведены любым желающим. Необходимые скрипты и дополнительные материалы доступны на GitHub проекта \cite{firsov2024project}.


\section{Заключение}


В рамках данной работы был предложен и реализован алгоритм для классификации товаров по кодам ОКПД2. Разработанная модель основывается на использовании текстовых эмбеддингов и логистической регрессии, что позволило эффективно решать задачу многоклассовой классификации. Было проведено тщательное исследование модели, в ходе которого анализировалось влияние глубины классификатора на качество результатов, а также изучено, как различные гиперпараметры влияют на производительность модели.

Кроме того, в работе были исследованы различные способы улучшения модели, включая модификации алгоритма классификации и применение иерархической структуры классификатора, что позволило улучшить точность классификации, особенно на более глубоких уровнях.

Возможные пути для дальнейших улучшений модели включают:

\begin{itemize}
    \item Улучшение качества текстовых эмбеддингов, возможно, за счет использования более совершенных моделей нейронных сетей или дополнительного дообучения на специфических данных.
    \item Интеграция и усовершенствование предложенных методов улучшения классификации для создания более робустной системы.
    \item Работа над несбалансированностью классов, что может включать техники ресемплинга или специализированные функции потерь.
\end{itemize}


\bibliographystyle{unsrtnat}
\bibliography{Firsov2024Classification_according_to_OKPD_2_codes}

\end{document}